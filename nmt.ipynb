{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_addons'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core \u001b[38;5;28;01mas\u001b[39;00m layers_core\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400000it [43:22, 537.90it/s]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3100000it [00:03, 1083646.05it/s]"
     ]
    }
   ],
   "source": [
    "enline, chline = None, None\n",
    "enlines, chlines = [], []\n",
    "sentence_length = 10\n",
    "file_path = './data/word/segmented_train_seg_by_word.txt'\n",
    "pbar = tqdm()\n",
    "i = 0\n",
    "early_exist_line_num = 1000000\n",
    "with open(file_path, 'r') as lines:\n",
    "    for line in lines:\n",
    "        i += 1\n",
    "        if i % 2 == 1:\n",
    "            enline = line.lower().strip('\\n').split()\n",
    "            continue          \n",
    "        else:\n",
    "            chline =[w for w in line.strip('\\n').replace(' ','')]\n",
    "        if len(enline) > sentence_length and len(chline) > sentence_length:\n",
    "            continue    \n",
    "        enlines.append(enline)\n",
    "        chlines.append(chline)  \n",
    "        if i % 100000 == 0:\n",
    "            pbar.update(i)  \n",
    "        if i == early_exist_line_num:\n",
    "            break\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301514"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['一', '对', '二', '总', '不', '是', '好', '事', '，'], ['一', '对', '二', '胜', '。'], ['一', '对', '五', '年', '没', '见', '过', '的', '姐', '妹', '一', '场', '激', '烈', '的', '争', '吵', '？'], ['一', '对', '五', '百', '诶', '。']]\n",
      "[['fighting', 'two', 'against', 'one', 'is', 'never', 'ideal', ','], ['deuces', 'the', 'winner', '.'], ['an', 'incredibly', 'emotional', 'fight', 'between', '2', 'sisters', '？'], ['one', 'against', '500', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(chlines[:4])\n",
    "print(enlines[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addchar(word2id, id2word, word):\n",
    "    id = len(word2id)\n",
    "    word2id[word] = id\n",
    "    id2word[id] = word\n",
    "\n",
    "ch2id, id2ch, en2id, id2en = {}, {}, {},{}\n",
    "most_common_k = 100000\n",
    "specialchars = ['<eos>','<start>','<end>','<unk>']\n",
    "\n",
    "chwords, enwords = set(), set()\n",
    "for ch in chlines: \n",
    "    for c in ch:\n",
    "        chwords.add(c)\n",
    "for en in enlines: \n",
    "    for e in en:\n",
    "        enwords.add(e)\n",
    "\n",
    "for word, _ in Counter(chwords).most_common(most_common_k):\n",
    "    addchar(ch2id, id2ch, word)\n",
    "    \n",
    "for word, _ in Counter(enwords).most_common(most_common_k):\n",
    "    addchar(en2id, id2en, word)\n",
    "    \n",
    "for one in specialchars:\n",
    "    addchar(ch2id,id2ch,one)\n",
    "    addchar(en2id,id2en,one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47028, 4770)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3100000it [00:21, 1083646.05it/s]"
     ]
    }
   ],
   "source": [
    "len(en2id), len(ch2id)\n",
    "# ch2id['<unk>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for english to chinese translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_x_in, dat_y_in,dat_y_out =[], [], []\n",
    "dat_x_len, dat_y_len = [], []\n",
    "unknown_en_id = en2id['<unk>']\n",
    "eos_en_id = en2id['<eos>']\n",
    "# english sentences to id array\n",
    "for en_sentence in enlines:\n",
    "    id_en_sentence = [ en2id.get(w, unknown_en_id) for w in en_sentence ]\n",
    "    id_en_sentence.append(eos_en_id) #mark end of sentence\n",
    "    dat_x_in.append(id_en_sentence)\n",
    "    dat_x_len.append(len(id_en_sentence))\n",
    "    \n",
    "# chinse sentences to id array\n",
    "start_ch_id = ch2id['<start>']\n",
    "end_ch_id = ch2id['<end>']\n",
    "unknown_ch_id = ch2id['<unk>']\n",
    "for ch_sentence in chlines:\n",
    "    id_ch_sentence = [ ch2id.get(w, unknown_ch_id) for w in ch_sentence ]\n",
    "    dat_y_in.append([start_ch_id] + id_ch_sentence)\n",
    "    dat_y_out.append(id_ch_sentence + [end_ch_id])\n",
    "    dat_y_len.append(len(id_ch_sentence) + 1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['one', 'pair', 'of', 'elongated', 'canines', '.', '<eos>'],\n",
       " ['<start>', '一', '对', '延', '长', '犬', '齿', '。'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 100\n",
    "[id2en[i] for i in dat_x_in[m]], [id2ch[i] for i in dat_y_in[m]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predit on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# df = pd.DataFrame()\n",
    "# df.to_csv('submission.csv',index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
