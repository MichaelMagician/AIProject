{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisonous Mushroom \n",
    "    - using fake random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data: https://www.kaggle.com/datasets/uciml/mushroom-classification/data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import BaseEstimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
      "0     p         x           s         n       t    p               f   \n",
      "1     e         x           s         y       t    a               f   \n",
      "\n",
      "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
      "0            c         n          k  ...                        s   \n",
      "1            c         b          k  ...                        s   \n",
      "\n",
      "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
      "0                      w                      w         p          w   \n",
      "1                      w                      w         p          w   \n",
      "\n",
      "  ring-number ring-type spore-print-color population habitat  \n",
      "0           o         p                 k          s       u  \n",
      "1           o         p                 n          n       g  \n",
      "\n",
      "[2 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/mushrooms.csv')\n",
    "print(data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummy_columns(data: pd.DataFrame, columns : list) -> pd.DataFrame :\n",
    "    # data = data.dropna()\n",
    "    for col in columns:        \n",
    "        new_column_suffix = data[col].apply(lambda x: str(x)).unique()\n",
    "        new_cols = [ col + '_' + suffix for suffix in new_column_suffix ]\n",
    "        new_data =pd.get_dummies(data[col], prefix=col)[new_cols]\n",
    "        data = pd.concat([data, new_data], axis=1) \n",
    "        del data[col]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cap-shape_x', 'cap-shape_b', 'cap-shape_s', 'cap-shape_f',\n",
      "       'cap-shape_k', 'cap-shape_c', 'cap-surface_s', 'cap-surface_y',\n",
      "       'cap-surface_f', 'cap-surface_g',\n",
      "       ...\n",
      "       'population_v', 'population_y', 'population_c', 'habitat_u',\n",
      "       'habitat_g', 'habitat_m', 'habitat_d', 'habitat_p', 'habitat_w',\n",
      "       'habitat_l'],\n",
      "      dtype='object', length=117)\n",
      "   cap-shape_x  cap-shape_b  cap-shape_s  cap-shape_f  cap-shape_k  \\\n",
      "0         True        False        False        False        False   \n",
      "1         True        False        False        False        False   \n",
      "\n",
      "   cap-shape_c  cap-surface_s  cap-surface_y  cap-surface_f  cap-surface_g  \\\n",
      "0        False           True          False          False          False   \n",
      "1        False           True          False          False          False   \n",
      "\n",
      "   ...  population_v  population_y  population_c  habitat_u  habitat_g  \\\n",
      "0  ...         False         False         False       True      False   \n",
      "1  ...         False         False         False      False       True   \n",
      "\n",
      "   habitat_m  habitat_d  habitat_p  habitat_w  habitat_l  \n",
      "0      False      False      False      False      False  \n",
      "1      False      False      False      False      False  \n",
      "\n",
      "[2 rows x 117 columns]\n"
     ]
    }
   ],
   "source": [
    "# fill missing and prepare dummy valiables\n",
    "# print(len(data))\n",
    "data.fillna('missing', inplace=True)\n",
    "data_x = data.iloc[:,1:]\n",
    "X = generate_dummy_columns(data_x, data_x.columns)\n",
    "Y = data['class'].apply(lambda x: +1 if x == 'p' else -1)\n",
    "\n",
    "print(X.columns)\n",
    "print(X.head(2))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare sk learn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9260029188161825\n",
      "DecisionTreeClassifier 0.9308194503704279\n",
      "RandomForestClassifier 0.9542182227221597\n"
     ]
    }
   ],
   "source": [
    "models = [LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier(n_estimators=10)]\n",
    "\n",
    "for model in models:\n",
    "    score = cross_val_score(model,X,Y, cv=8)\n",
    "    print(model.__class__.__name__, score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build fake random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeRanndomForest(BaseEstimator):\n",
    "    def __init__(self, M = 10):\n",
    "        self.M = M\n",
    "        self.models = []\n",
    "        self.features = []\n",
    "\n",
    "    def fit(self, X, Y, n_features=None):\n",
    "        if n_features is None:\n",
    "            n_features = int(np.sqrt(X.shape[1]))\n",
    "        N = len(X)\n",
    "\n",
    "        for i in range(self.M):\n",
    "            model = DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "            # select features randomly\n",
    "            selected_features_indexes = np.random.choice(X.shape[1], n_features, replace=False)            \n",
    "            selected_sample_indexes = np.random.choice(N, N, replace=False)\n",
    "            train_x = X.iloc[selected_sample_indexes, selected_features_indexes]\n",
    "            train_y = Y.iloc[selected_sample_indexes]\n",
    "\n",
    "            model.fit(train_x, train_y)\n",
    "            self.models.append(model)\n",
    "            self.features.append(selected_features_indexes)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(len(X))\n",
    "        for i, model in enumerate(self.models):\n",
    "            x_p = X.iloc[:, self.features[i]]\n",
    "            predictions += model.predict(x_p)\n",
    "        return np.sign(predictions/self.M)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaggedTree(BaseEstimator):\n",
    "    def __init__(self, M): \n",
    "        self.M = M  \n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        N = len(X)\n",
    "        \n",
    "        for i in range(self.M):\n",
    "            indexes = np.random.choice(N, size=N, replace=True)  \n",
    "            X_train = X.iloc[indexes,:]\n",
    "            Y_train = Y.iloc[indexes]  \n",
    "            model = DecisionTreeClassifier(max_depth=2)\n",
    "            model.fit(X_train, Y_train)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(len(X))\n",
    "        for i, model in enumerate(self.models):\n",
    "            predictions += model.predict(X)\n",
    "        return np.round(predictions/self.M)\n",
    "    \n",
    "    def score(self, X, Y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(Y, y_pred)      \n",
    "    \n",
    "model = BaggedTree(10)\n",
    "model.fit(X, Y)\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<__main__.BaggedTree object at 0x0000023F692DEF90>' (type <class '__main__.BaggedTree'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     tasks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ready_batches\u001b[39m.\u001b[39mget(block\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m queue\u001b[39m.\u001b[39mEmpty:\n\u001b[0;32m    864\u001b[0m     \u001b[39m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    865\u001b[0m     \u001b[39m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[39m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     \u001b[39m# workers.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\miche\\Career\\AI_training_code\\AIProject\\mushroom_fake_random_forest.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/miche/Career/AI_training_code/AIProject/mushroom_fake_random_forest.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m models \u001b[39m=\u001b[39m [BaggedTree(M\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m), FakeRanndomForest(M\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m) ]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/miche/Career/AI_training_code/AIProject/mushroom_fake_random_forest.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/miche/Career/AI_training_code/AIProject/mushroom_fake_random_forest.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# model.fit(X, Y)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/miche/Career/AI_training_code/AIProject/mushroom_fake_random_forest.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# r = model.predict(X)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/miche/Career/AI_training_code/AIProject/mushroom_fake_random_forest.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     score \u001b[39m=\u001b[39m cross_val_score(model,X,Y, cv\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/miche/Career/AI_training_code/AIProject/mushroom_fake_random_forest.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, score\u001b[39m.\u001b[39mmean())\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    564\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m    565\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    566\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[0;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m: scorer},\n\u001b[0;32m    568\u001b[0m     cv\u001b[39m=\u001b[39mcv,\n\u001b[0;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39mn_jobs,\n\u001b[0;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39mfit_params,\n\u001b[0;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39mpre_dispatch,\n\u001b[0;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39merror_score,\n\u001b[0;32m    574\u001b[0m )\n\u001b[0;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[0;32m    312\u001b[0m         X,\n\u001b[0;32m    313\u001b[0m         y,\n\u001b[0;32m    314\u001b[0m         scorers,\n\u001b[0;32m    315\u001b[0m         train,\n\u001b[0;32m    316\u001b[0m         test,\n\u001b[0;32m    317\u001b[0m         verbose,\n\u001b[0;32m    318\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    319\u001b[0m         fit_params,\n\u001b[0;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39mreturn_train_score,\n\u001b[0;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39mreturn_estimator,\n\u001b[0;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    870\u001b[0m n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    871\u001b[0m big_batch_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m n_jobs\n\u001b[1;32m--> 873\u001b[0m islice \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(itertools\u001b[39m.\u001b[39mislice(iterator, big_batch_size))\n\u001b[0;32m    874\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(islice) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    875\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:61\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m---> 61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:311\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m--> 311\u001b[0m         clone(estimator),\n\u001b[0;32m    312\u001b[0m         X,\n\u001b[0;32m    313\u001b[0m         y,\n\u001b[0;32m    314\u001b[0m         scorers,\n\u001b[0;32m    315\u001b[0m         train,\n\u001b[0;32m    316\u001b[0m         test,\n\u001b[0;32m    317\u001b[0m         verbose,\n\u001b[0;32m    318\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    319\u001b[0m         fit_params,\n\u001b[0;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39mreturn_train_score,\n\u001b[0;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39mreturn_estimator,\n\u001b[0;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:76\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39m__sklearn_clone__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m inspect\u001b[39m.\u001b[39misclass(estimator):\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39m__sklearn_clone__()\n\u001b[1;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m _clone_parametrized(estimator, safe\u001b[39m=\u001b[39msafe)\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:97\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     92\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou should provide an instance of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mscikit-learn estimator instead of a class.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m             )\n\u001b[0;32m     96\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     98\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mit does not seem to be a scikit-learn \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mestimator as it does not implement a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m'\u001b[39m\u001b[39m method.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mrepr\u001b[39m(estimator), \u001b[39mtype\u001b[39m(estimator))\n\u001b[0;32m    102\u001b[0m             )\n\u001b[0;32m    104\u001b[0m klass \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\n\u001b[0;32m    105\u001b[0m new_object_params \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot clone object '<__main__.BaggedTree object at 0x0000023F692DEF90>' (type <class '__main__.BaggedTree'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "models = [BaggedTree(M=100), FakeRanndomForest(M=100) ]\n",
    "\n",
    "for model in models:\n",
    "    # model.fit(X, Y)\n",
    "    # r = model.predict(X)\n",
    "    score = cross_val_score(model,X,Y, cv=4)\n",
    "    print(model.__class__.__name__, score.mean())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predit on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.DataFrame()\n",
    "# df.to_csv('submission.csv',index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
