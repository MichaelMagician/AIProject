{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendations with collaborative recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from collections import defaultdict\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp\n",
      "0       1      296     5.0  1147880044\n",
      "1       1      306     3.5  1147868817\n",
      "2       1      307     5.0  1147868828\n",
      "3       1      665     5.0  1147878820\n",
      "4       1      899     3.5  1147868510\n",
      "5       1     1088     4.0  1147868495\n",
      "6       1     1175     3.5  1147868826\n",
      "7       1     1217     3.5  1147878326\n",
      "8       1     1237     5.0  1147868839\n",
      "9       1     1250     4.0  1147868414\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('./data/ml-25m/ratings.csv', nrows=10000)\n",
    "print(train_data.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId\n",
      "1      70\n",
      "2     184\n",
      "3     656\n",
      "4     242\n",
      "5     101\n",
      "     ... \n",
      "71     36\n",
      "72    813\n",
      "73     39\n",
      "74     22\n",
      "75     61\n",
      "Length: 75, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "popularity = train_data.groupby(train_data['userId']).size()\n",
    "print(popularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m users \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m      6\u001b[0m user_movie_dict \u001b[38;5;241m=\u001b[39m get_user_movie_dict(train_data) \n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(users))\n",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m users \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m      6\u001b[0m user_movie_dict \u001b[38;5;241m=\u001b[39m get_user_movie_dict(train_data) \n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(users))\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# user to movies dictionary\n",
    "def get_user_movie_dict(data: pd.DataFrame):\n",
    "    return {key: values for (key, values) in data.groupby('userId')}\n",
    "\n",
    "users = list(set(train_data['userId']))\n",
    "user_movie_dict = get_user_movie_dict(train_data) \n",
    "print(len(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_user_similarity(user_movie_dict, users) -> dict: \n",
    "    'dict: {u: {v:score}} '\n",
    "    similarity_scores_dict = defaultdict(dict)\n",
    "    \n",
    "    for i in range(len(users)):\n",
    "        for j in range(i + 1 ,len(users)):\n",
    "            u = users[i]\n",
    "            v = users[j]\n",
    "            u_movies = set(user_movie_dict[u]['movieId'].to_list())\n",
    "            v_movies = set(user_movie_dict[v]['movieId'].to_list())\n",
    "            movies_common = u_movies.intersection(v_movies)\n",
    "            \n",
    "            score = len(movies_common) / np.sqrt(len(u_movies) * len(v_movies))            \n",
    "            similarity_scores_dict[u][v]= score            \n",
    "            similarity_scores_dict[v][u]=score\n",
    "    return similarity_scores_dict\n",
    "\n",
    "user_similarity_score = calculate_user_similarity(user_movie_dict, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(55, 0.13522468075656266), (68, 0.1119980089419836), (50, 0.10624254305194611), (38, 0.09089344255870231), (37, 0.08964214570007951)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_top_k_similar_users(user_id: int|str, user_similarity_score : dict, k: int = 10) -> List: \n",
    "    'return user, movies, similarity score'\n",
    "    similar_users = user_similarity_score[user_id] # {v1:0.2, v3: 0.3}\n",
    "    res = sorted(similar_users.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [x for x in res[:k]]\n",
    "    \n",
    "similar_users = get_top_k_similar_users(1, user_similarity_score, 5)\n",
    "print(similar_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[593, 2858, 2959, 4226, 2571, 6874, 4993, 356, 260, 318, 2329, 50, 46578, 60069, 527, 7153, 7438, 110, 3578, 58559]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def recommended_movies(user_id, user_movie_dict, user_similarity_score,  k):\n",
    "    candidate_movies = defaultdict(float) # movie_id, recommendation score\n",
    "    # find top N similar users    \n",
    "    user_watched_movies = set(user_movie_dict[user_id]['movieId'].to_list())\n",
    "    similar_users = get_top_k_similar_users(user_id, user_similarity_score,  k)\n",
    "    \n",
    "    for user_v, similarity_score in similar_users:\n",
    "        user_v_movies = user_movie_dict[user_v]\n",
    "        for index, movie in user_v_movies.iterrows():\n",
    "            if movie['movieId'] not in user_watched_movies:\n",
    "                candidate_movies[movie['movieId']] += similarity_score * movie['rating']\n",
    "\n",
    "    recommendation = sorted(candidate_movies.items(), key=lambda mv: mv[1], reverse=True)\n",
    "    return [int(x[0]) for x in recommendation[:k]]\n",
    "\n",
    "suggestions = recommended_movies(1, user_movie_dict, user_similarity_score, 20)\n",
    "print(suggestions)\n",
    "\n",
    "m = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find user similarities\n",
    "# given user U, find top K similar users\n",
    "# foreach similar user v, get movies that U hasn't watched. And calculate movie recommendation score for each movie\n",
    "# sort candidate movies by recommendation scores and pick the top K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predit on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.DataFrame()\n",
    "# df.to_csv('submission.csv',index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
